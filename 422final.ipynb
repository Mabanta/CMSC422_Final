{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Music Genre Classification based on Audio Analysis\n",
    "\n",
    "##### Last updated on December 6th, 2022 by Matthew Lynch and Kalonji Harrington"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## “Pop” music vs “Popular” music?\n",
    "\n",
    "When people use the term “*pop music*” they could be referring either to popular music (as in music that is popular or trending) or a more specific genre distinct from metal, jazz, rap, indie, and other established genres. The discussion as to what constitutes the genre of pop music is a complicated one as the genre continuously evolves–branching out and [borrowing musical elements from other styles like rock, dance, Latin, and country music](https://en.wikipedia.org/wiki/Pop_music). The genre of pop also typically aligns with what is currently popular at a given time and Wikipedia suggests *“that the term \"pop music\" may be used to describe a distinct genre, designed to appeal to all.”* Yet when examining the top hits from the last two decades, there are some tracks that probably wouldn’t be considered as emblematic of the “pop” genre, but rather a subgenre or a different style altogether.\n",
    "\n",
    "The discussion of popular music is also complex as the current notion of *“good”* music relies heavily on subjective opinions influenced by our culture today. The types of songs that are popular in the United States in 2022 differs from the hit songs of 2005 and might not even be the same as what is currently trending in other countires like Spain or South Korea. Because of this I want to make it clear that the goal of this project is **not to define what** ***\"good\"*** **music is** but merely to examine trends in the most frequently played tracks.\n",
    "\n",
    "To clarify, for this project rather than analyzing music from a particular genre, I am analyzing **popular music in the United States from January 1st, 2000 to today** (March 16th, 2022) with the intent of determining if certain combinations of musical qualities are more likely to create hit songs than others. While the process of creating music isn't necessarily so straightforward, information about what the most popular song duration, tempo, key signature, or even volume could provide a guideline for people who wish to create their own popular music."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Billboard Hot 100\n",
    "\n",
    "To determine which songs are the most popular, I chose to use [Billboard charts](https://www.billboard.com/charts/). I wanted data on the most popular songs within the United States and for how long they have been popular without relying on a specific streaming service. While music streaming services keep track of how often a song is played, managing to collect the total number of times a given track has been played on different services would be an incredibly time consuming task. When searching for an alternative, I found [Billboard Magazine](https://www.billboard.com/) which focuses its brand on constructing charts and reporting on music news and trends across different genres of music. The Billboard Hot 100 acts as a [music industry standard record chart](https://en.wikipedia.org/wiki/Billboard_Hot_100) and provides information taking into considering all of the most common ways to consume music today. The tooltip on the Hot 100 Charts says the following:\n",
    "\n",
    "> The week’s most popular songs, ranked by audio and video streaming activity on leading digital music services, radio airplay audience impressions based on monitored airplay and sales data, all compiled by Luminate. Audience totals are derived, in part, using certain Nielsen Audio listener estimates.”\n",
    "\n",
    "They also provide a variety of charts such as the Billboard Global 200, Billboard Global Excluding US, Hot Country Songs, Top Latin Albums, and more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Spotify Web Api\n",
    "\n",
    "After using the Billboard Hot 100 charts to obtain a list of popular songs, I looked for other websites to scrape relevant song data from. After spending some time looking, I ended up deciding to use [Spotify's Web API](https://developer.spotify.com/). The API provides access to user specfic data such as playlists and saved music alongside more general public data, such as information about the tracks Spotify has access to. This project doesn't need user specific information, so only client side authentication was needed.\n",
    "\n",
    "After creating an account with Spotify, I created a project on the dashboard to obtain the client side credentials needed to access the Web API. With those credentials I was able to use the python library [spotipy](https://spotipy.readthedocs.io/en/2.19.0/#) to run the API within python. For the authentication, I stored the clientID and clientSecretID on my local device in a file name `config.py` \n",
    "\n",
    "If you are trying to run this project yourself, make sure to create a `config.py` on your local device and add your credentials to it. The `import config` will allow this project to access the credentials and subsequently allow proper requests to the Web API.\n",
    "\n",
    "The Spotify Web API was used to obtain Spotify's audio analysis data which analyzes samples from a given track and records values for duration, loudness, tempo, time signature, tempo, key, and the mode (minor or major) of the song along with the corresponding confidence values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Collection\n",
    "\n",
    "Now with all of the basic information covered, we can now go ahead with obtaining the data. Throughout the project, the dataframes are exported to csv files which are considerably faster to read than manually scraping the data gain as there are a lot of weeks in over two decades with each week having 100 songs each.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Collecting Billboard Top 100 Data\n",
    "\n",
    "To begin, we first want to scrape the information from the Billboard Hot 100 pages. We're looking to obtain the ranking of each song, the song titles, the artist names, and the number of weeks the song has been in the Hot 100. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for data collection\n",
    "import pandas as pd\n",
    "import requests as rq\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import datetime as dt\n",
    "import re\n",
    "\n",
    "# Returns a formatted string from a datetime to use when scraping Billboard charts\n",
    "def format_datetime(datetime):\n",
    "    return str(datetime.year).zfill(4) + \"-\" + str(datetime.month).zfill(2) + \"-\" + str(datetime.day).zfill(2) \n",
    "\n",
    "# Returns a formatted string given a string containing artist name(s)\n",
    "def format_name(name):\n",
    "    # Fixes the formatting of the ampersand\n",
    "    amp = re.sub('&amp;', \"&\", name)\n",
    "    # Standardizes ways of featuring an artist to \"ft.\"\n",
    "    ft = re.sub('(Featuring)|(featuring)|(feat\\.?)', \"ft.\", amp)\n",
    "    return ft\n",
    "\n",
    "# Removes html tags from a string\n",
    "def remove_tags(tag, string):\n",
    "    tag1 ='<' + tag + '.*?>\\s*'\n",
    "    tag2 = '\\s*</' + tag + '.*?>'\n",
    "    return re.sub(tag2, \"\", re.sub(tag1, \"\", string))\n",
    "\n",
    "# Scrapes data from a specified billboard page in a given period of time\n",
    "def scrape_billboard(start_date, end_date, page):\n",
    "    info_list = []\n",
    "    date = start_date\n",
    "    # Continues to scrape from new pages until the end date is reached\n",
    "    while date <= end_date:\n",
    "        # Access the proper url given the date\n",
    "        billboard_url = \"https://www.billboard.com/\"  + page + format_datetime(date) + \"/\"\n",
    "        soup = bs(rq.get(billboard_url).content)\n",
    "        # Look for individual song entries\n",
    "        charts = soup.find_all(\"div\", class_=re.compile('o-chart-results-list-row-container'))\n",
    "        for entry in charts:\n",
    "            # Scrape the data from the chart\n",
    "            rank = remove_tags(\"span\", str(entry.find(\"span\", class_=re.compile('c-label a-font-primary-bold-l'))))\n",
    "            title = remove_tags(\"h3\", str(entry.find(\"h3\", class_=re.compile('c-title'))))\n",
    "            artist = remove_tags(\"span\", str(entry.find(\"span\", class_=re.compile('c-label a-no-trucate'))))\n",
    "            # Properly format the title and artist for ease of use later\n",
    "            title = format_name(title)\n",
    "            artist = format_name(artist)\n",
    "            # Find Last_Week, Peak_Pos, and Wks_on_Chart info\n",
    "            search = entry.find_all(\"span\", class_=re.compile('(c-label a-font-primary-m lrv-u-padding-tb-050@mobile-max)|(c-label a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max)'))\n",
    "            \"c-label a-font-primary-bold-l a-font-primary-m@mobile-max u-font-weight-normal@mobile-max\"\n",
    "            # Grab the data on the weeks on the chart\n",
    "            weeks = remove_tags(\"span\", str(search[2]))\n",
    "\n",
    "            # Add the data to the info_list\n",
    "            page_name = \"Weeks_in_\" + re.sub('charts/|/', \"_\", page).strip(\"_\")\n",
    "            data = {'Rank': rank, 'Title': title, 'Artist': artist, 'Week': date, page_name: weeks}\n",
    "            info_list.append(data)\n",
    "        # Increment the date by a week (Billboard's charts are on a weekly basis)\n",
    "        date += dt.timedelta(days = 7)\n",
    "    # Return a dataframe from the info_list\n",
    "    return pd.DataFrame(info_list)\n",
    "\n",
    "# Scrape hot-100 data from 01-01-2000 to today\n",
    "# billboard_data = scrape_billboard(dt.date(2000, 1, 1), dt.date.today(), \"charts/hot-100/\")\n",
    "# Track the first and last week a track enters the hot-100 charts instead of each week that the data is in the hot-100\n",
    "# billboard_data.insert(5, \"First_Week\", billboard_data['Week'], False)\n",
    "# billboard_data.insert(6, \"Last_Week\", billboard_data['Week'], False)\n",
    "# billboard_data.drop(columns=['Week'], inplace=True)\n",
    "\n",
    "# Export to a csv to save time in subsequent calls\n",
    "# billboard_data.to_csv(\"csv/billboard_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While we could have used global data instead of the Hot 100, I chose to use the Hot 100 as I am personally more familiar with the music in the United States. I don't have a reference point for what is popular overseas, so the data within the United States makes more sense for me to process given that I would likely create music for the United States market in mind. It is entirely feasible to look at the different charts instead of the Hot 100 if so desired. The `page` parameter in `scrape_billboard()` allows different charts to be passed using the same function definition.\n",
    "\n",
    "Additionally, although we haven't finished scraping all of the data (since we haven't used the Spotify Web API just yet), I went ahead and started to format the data just to make additional scraping easier. The Billboard Hot 100 charts formatted ampersands differently, so I replaced their string with a simple ampersand just to make the subsequent regular expressions easier to handle. I also standardized the usage of \"Featuring\" or \"featuring\" or \"feat.\" to just be \"ft.\" since consistent expressions are easier to handle."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Collecting Spotify Data Based On Billboard Data\n",
    "\n",
    "Now that the data from the Billboard charts has been collected, we can now group the data by the titles (removing duplicate entries) and extract other information using Spotify's API. The grouping is done mainly to save time as otherwise we would be extracting the same information from a song multiple times if it appears on the charts multiple weeks in a row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries for spotipy and the config file needed to authenticate our client\n",
    "import spotipy\n",
    "from spotipy.oauth2 import SpotifyClientCredentials\n",
    "import config\n",
    "\n",
    "# Read the billboard data and drop the extra row from the index\n",
    "billboard_data = pd.read_csv(\"csv/billboard_data.csv\").iloc[:, 1:]\n",
    "\n",
    "# Group the data properly using the specified aggregation functions\n",
    "aggregation_functions = {'Rank': \"min\", 'Weeks_in_hot-100': \"max\", 'First_Week': \"min\", 'Last_Week': \"max\"}\n",
    "spotify_data = billboard_data.groupby(['Title', 'Artist']).aggregate(aggregation_functions).reset_index()\n",
    "\n",
    "# Effectively relabel the Rank row as Top Rank\n",
    "spotify_data.insert(0, \"Top_Rank\", spotify_data['Rank'], False)\n",
    "spotify_data.drop(columns=['Rank'], inplace=True)\n",
    "\n",
    "# Create an instance of spotipy and store the authentication token with the client credential manager\n",
    "authentication = SpotifyClientCredentials(client_id=config.cid, client_secret=config.csecret)\n",
    "sp = spotipy.Spotify(client_credentials_manager=authentication)\n",
    "\n",
    "# Returns an array with all of the analysis data based on the query results given an artist and a song title\n",
    "def get_audio_analysis(artist, title):\n",
    "    # Specify the artist to avoid picking a random song\n",
    "    q = \"{} artist:{}\".format(title, artist)\n",
    "    result = sp.search(q, type='track', limit=1)['tracks']['items']\n",
    "    # Check if the search was sucessful\n",
    "    if result == []:\n",
    "        # If the initial search failed, try again specifying w/ the track tag\n",
    "        q = \"track:{} artist:{}\".format(title, artist)\n",
    "        result = sp.search(q, type='track', limit=1)['tracks']['items']\n",
    "        # Check if it failed again\n",
    "        if result == []:\n",
    "            # No result was able to be found\n",
    "            return [None, None, None, None, None, None, None, None, None, None]\n",
    "    \n",
    "    # Get the SpotifyID from the given search (used for uniquely identifying a track)\n",
    "    spotify_id = result[0]['id']\n",
    "    # Try to run the audio analysis (some songs don't have audio analysis yet or don't exist in Spotify's library)\n",
    "    try:\n",
    "        analysis = sp.audio_analysis(spotify_id)\n",
    "    except spotipy.client.SpotifyException:\n",
    "        # If it failed, no result was found\n",
    "        return [None, None, None, None, None, None, None, None, None, None]\n",
    "\n",
    "    # Find the relevant information from the analysis\n",
    "    duration = analysis['track']['duration']\n",
    "    loudness = analysis['track']['loudness']\n",
    "    tempo = analysis['track']['tempo']\n",
    "    tempo_conf = analysis['track']['tempo_confidence']\n",
    "    time_sig = analysis['track']['time_signature']\n",
    "    time_sig_conf = analysis['track']['time_signature_confidence']\n",
    "    key = analysis['track']['key']\n",
    "    key_conf = analysis['track']['key_confidence']\n",
    "    mode = analysis['track']['mode']\n",
    "    mode_conf = analysis['track']['mode_confidence']\n",
    "    # Return the array\n",
    "    return [duration, loudness, tempo, tempo_conf, time_sig, time_sig_conf, key, key_conf, mode, mode_conf]\n",
    "\n",
    "# Declare empy lists for each variable\n",
    "duration_list = []\n",
    "loudness_list = []\n",
    "tempo_list = []\n",
    "tempo_conf_list = []\n",
    "time_sig_list = []\n",
    "time_sig_conf_list = []\n",
    "key_list = []\n",
    "key_conf_list =[]\n",
    "mode_list = []\n",
    "mode_conf_list = []\n",
    "\n",
    "# Run the analysis for each unique title in the dataset\n",
    "for index, row in spotify_data.iterrows():\n",
    "    # Create a list of artists, removing all other characters\n",
    "    string = re.sub('\\(|\\)', \", \", re.sub('\\s+((ft\\.)|&|X|x|(\\+)|/)\\s+', \", \", row['Artist'])).strip(', ')\n",
    "    artist_list = string.split(\",\")\n",
    "\n",
    "    # Try running the analysis until a result if found (sometimes searching an artist wouldn't yield proper results)\n",
    "    # i.e. \"Leave the Door Open\" by Silk Sonic, Bruno Mars, ... would only produce a result if Bruno Mars was used\n",
    "    values = [None, None, None, None, None, None, None, None, None, None]\n",
    "    for artist in artist_list:\n",
    "        if values == [None, None, None, None, None, None, None, None, None, None]:\n",
    "            # Remove parenthesis from the title to avoid the title being too long\n",
    "            # This was an issue with a Taylor Swift's Christmas Tree Farm (Old Timey Version)\n",
    "            values = get_audio_analysis(artist, re.sub('\\(.*\\)', \"\", row['Title']))\n",
    "    \n",
    "    # Add the results from the analysis to the lists\n",
    "    duration_list.append(values[0])\n",
    "    loudness_list.append(values[1])\n",
    "    tempo_list.append(values[2])\n",
    "    tempo_conf_list.append(values[3])\n",
    "    time_sig_list.append(values[4])\n",
    "    time_sig_conf_list.append(values[5])\n",
    "    key_list.append(values[6])\n",
    "    key_conf_list.append(values[7])\n",
    "    mode_list.append(values[8])\n",
    "    mode_conf_list.append(values[9])\n",
    "\n",
    "# Add the data to the dataframe\n",
    "spotify_data.insert(6, \"Duration\", duration_list, False)\n",
    "spotify_data.insert(7, \"Loudness\", loudness_list, False)\n",
    "spotify_data.insert(8, \"Tempo\", tempo_list, False)\n",
    "spotify_data.insert(9, \"Tempo_Confidence\", tempo_conf_list, False)\n",
    "spotify_data.insert(10, \"Meter\", time_sig_list, False)\n",
    "spotify_data.insert(11, \"Meter_Confidence\", time_sig_conf_list, False)\n",
    "spotify_data.insert(12, \"Key\", key_list, False)\n",
    "spotify_data.insert(13, \"Key_Confidence\", key_conf_list, False)\n",
    "spotify_data.insert(14, \"Mode\", mode_list, False)\n",
    "spotify_data.insert(15, \"Mode_Confidence\", mode_conf_list, False)\n",
    "\n",
    "# Export the spotify data to a csv\n",
    "# spotify_data.to_csv(\"csv/spotify_data_2000_01_01.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There were a few problems that I encountered when working on using the Spotify Web API to querey results. The first issue was when songs that were on Spotify weren't being properly found. Some songs like *Leave The Door Open* by Bruno Mars, Anderson .Paak, and Silk Sonic had some issues due to how complicated the original artist string was. Directly imported from the Billboard charts, the artist strings for each song could be formatted in multiple different ways. After running the below code, I was able to find patterns in songs that failed to properly query. The solution was converting the artists strings into a list of individual artists who are credited for the song and searching multiple times with each artist to maximize the chance that the correct song is chosen. Another similar issue I noticed was with *Christmas Tree Farm (Old Timey Version)* by Taylor Swift as the parenthesis made the query too long for the API to properly handle.\n",
    "\n",
    "Additionally some songs don't have the audo analysis available in Spoity's API. Some songs like Camila Cabello's *I'll Be Home for Christmas* is only available on Amazon Music and other songs like Shawn Mendes' *Lost in Japan* didn't have an available audio analysis in the API and returned:\n",
    "\n",
    "`HTTP Error for GET to https://api.spotify.com/v1/audio-analysis/0BXTqB4It8UM09lCaIY3Jk with Params: {} returned 404 due to analysis not found`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tracks: 8486\n",
      "Total number of tracks w/ missing data: 269\n",
      "Percentage of data with complete data: 96.83007306151308%\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top_Rank</th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Weeks_in_hot-100</th>\n",
       "      <th>First_Week</th>\n",
       "      <th>Last_Week</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Tempo_Confidence</th>\n",
       "      <th>Meter</th>\n",
       "      <th>Meter_Confidence</th>\n",
       "      <th>Key</th>\n",
       "      <th>Key_Confidence</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mode_Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>59</td>\n",
       "      <td>15 Minutes</td>\n",
       "      <td>Marc Nelson</td>\n",
       "      <td>16</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2000-01-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>144</th>\n",
       "      <td>57</td>\n",
       "      <td>9 AM In Dallas</td>\n",
       "      <td>Drake</td>\n",
       "      <td>1</td>\n",
       "      <td>2010-07-03</td>\n",
       "      <td>2010-07-03</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>148</th>\n",
       "      <td>8</td>\n",
       "      <td>95.south</td>\n",
       "      <td>J. Cole</td>\n",
       "      <td>3</td>\n",
       "      <td>2021-05-29</td>\n",
       "      <td>2021-06-12</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>66</td>\n",
       "      <td>A Broken Wing</td>\n",
       "      <td>Jordin Sparks</td>\n",
       "      <td>2</td>\n",
       "      <td>2007-06-09</td>\n",
       "      <td>2007-06-16</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>156</th>\n",
       "      <td>56</td>\n",
       "      <td>A Change Is Gonna Come</td>\n",
       "      <td>Adam Lambert</td>\n",
       "      <td>1</td>\n",
       "      <td>2009-06-06</td>\n",
       "      <td>2009-06-06</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>157</th>\n",
       "      <td>75</td>\n",
       "      <td>A Country Boy Can Survive (Y2K Version)</td>\n",
       "      <td>Chad Brock With Hank Williams Jr. &amp; George Jones</td>\n",
       "      <td>3</td>\n",
       "      <td>2000-01-01</td>\n",
       "      <td>2000-01-15</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>37</td>\n",
       "      <td>Ain't No Sunshine</td>\n",
       "      <td>Kris Allen</td>\n",
       "      <td>2</td>\n",
       "      <td>2009-06-06</td>\n",
       "      <td>2009-06-13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>77</td>\n",
       "      <td>All These N**gas</td>\n",
       "      <td>King Von ft. Lil Durk</td>\n",
       "      <td>1</td>\n",
       "      <td>2020-11-21</td>\n",
       "      <td>2020-11-21</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>378</th>\n",
       "      <td>67</td>\n",
       "      <td>Always Be My Baby</td>\n",
       "      <td>David Cook</td>\n",
       "      <td>1</td>\n",
       "      <td>2008-06-07</td>\n",
       "      <td>2008-06-07</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>67</td>\n",
       "      <td>And Then What</td>\n",
       "      <td>Young Jeezy ft. Mannie Fresh</td>\n",
       "      <td>11</td>\n",
       "      <td>2005-07-23</td>\n",
       "      <td>2005-10-01</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Top_Rank                                    Title  \\\n",
       "44         59                               15 Minutes   \n",
       "144        57                           9 AM In Dallas   \n",
       "148         8                                 95.south   \n",
       "154        66                            A Broken Wing   \n",
       "156        56                   A Change Is Gonna Come   \n",
       "157        75  A Country Boy Can Survive (Y2K Version)   \n",
       "269        37                        Ain't No Sunshine   \n",
       "348        77                         All These N**gas   \n",
       "378        67                        Always Be My Baby   \n",
       "419        67                            And Then What   \n",
       "\n",
       "                                               Artist  Weeks_in_hot-100  \\\n",
       "44                                        Marc Nelson                16   \n",
       "144                                             Drake                 1   \n",
       "148                                           J. Cole                 3   \n",
       "154                                     Jordin Sparks                 2   \n",
       "156                                      Adam Lambert                 1   \n",
       "157  Chad Brock With Hank Williams Jr. & George Jones                 3   \n",
       "269                                        Kris Allen                 2   \n",
       "348                             King Von ft. Lil Durk                 1   \n",
       "378                                        David Cook                 1   \n",
       "419                      Young Jeezy ft. Mannie Fresh                11   \n",
       "\n",
       "     First_Week   Last_Week  Duration  Loudness  Tempo  Tempo_Confidence  \\\n",
       "44   2000-01-01  2000-01-15       NaN       NaN    NaN               NaN   \n",
       "144  2010-07-03  2010-07-03       NaN       NaN    NaN               NaN   \n",
       "148  2021-05-29  2021-06-12       NaN       NaN    NaN               NaN   \n",
       "154  2007-06-09  2007-06-16       NaN       NaN    NaN               NaN   \n",
       "156  2009-06-06  2009-06-06       NaN       NaN    NaN               NaN   \n",
       "157  2000-01-01  2000-01-15       NaN       NaN    NaN               NaN   \n",
       "269  2009-06-06  2009-06-13       NaN       NaN    NaN               NaN   \n",
       "348  2020-11-21  2020-11-21       NaN       NaN    NaN               NaN   \n",
       "378  2008-06-07  2008-06-07       NaN       NaN    NaN               NaN   \n",
       "419  2005-07-23  2005-10-01       NaN       NaN    NaN               NaN   \n",
       "\n",
       "     Meter  Meter_Confidence  Key  Key_Confidence  Mode  Mode_Confidence  \n",
       "44     NaN               NaN  NaN             NaN   NaN              NaN  \n",
       "144    NaN               NaN  NaN             NaN   NaN              NaN  \n",
       "148    NaN               NaN  NaN             NaN   NaN              NaN  \n",
       "154    NaN               NaN  NaN             NaN   NaN              NaN  \n",
       "156    NaN               NaN  NaN             NaN   NaN              NaN  \n",
       "157    NaN               NaN  NaN             NaN   NaN              NaN  \n",
       "269    NaN               NaN  NaN             NaN   NaN              NaN  \n",
       "348    NaN               NaN  NaN             NaN   NaN              NaN  \n",
       "378    NaN               NaN  NaN             NaN   NaN              NaN  \n",
       "419    NaN               NaN  NaN             NaN   NaN              NaN  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the Spotify and Billboard data combined\n",
    "df = pd.read_csv(\"csv/spotify_data_2000_01_01.csv\").iloc[:, 1:]\n",
    "# Create a dataframe with only the missing values\n",
    "null_data = df[df.isnull().any(axis=1)]\n",
    "\n",
    "# Print info about missing data\n",
    "print(\"Total number of tracks: \" + str(len(df.index)))\n",
    "print(\"Total number of tracks w/ missing data: \" + str(len(null_data.index)))\n",
    "print(\"Percentage of data with complete data: \" + str(100*(1- len(null_data.index)/len(df.index))) + \"%\")\n",
    "\n",
    "# Display some of the missing songs\n",
    "null_data.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the data is only missing 269 out of 8486 different tracks. In the future I may go back and find other methods of accessing the missing data using other APIs, through I would need to adjust for the potential differences in how the missing data is calculated in comparison to Spotify's audio analysis.\n",
    "\n",
    "Spotify also had another way of obtaining data through the *Get Tracks' Audio Features* as opposed to the *Get Track's Audio Analysis*, however, I chose not to use the audio features to fill the missing data as the audio features lacks the confidence data that I collected from the audio analysis call. The confidence data is a floating point value from 0 to 1 that indicates the confiendce of Spotify's prediction of a value (key, time signature, etc.). It's also worth noting that Spotify also created their own metrics such as \"Acouticness\", \"Danceability\", \"Speechiness\", and \"Valence\", but seeing as these metrics were less well defined (i.e. Valence refers to the \"musical positiveness conveyed by a track\") and the methods for obtaining such data was more ambiguous, I decided to omit them from this dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Data Representation\n",
    "\n",
    "The goal now is to make the data more readable and easier to work with. To begin with we can drop the missing data from the dataframe. I would claim that the data is missing at random since there isn't an obvious trend as to why particular songs don't have an audio analysis for them. Additionally the songs that are missing due to not being available on Spotify are also missing at random as the list of popular music was obtained through scraping the Billboard Hot 100 charts which doesn't value which services a song is avaiable through.\n",
    "\n",
    "The values of some of the columns were also adjusted to go from their floating point representations to strings that are more easily understood. For example, the key of a song is now represented with a letter name as opposed to a float between -1 and 11."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Top_Rank</th>\n",
       "      <th>Title</th>\n",
       "      <th>Artist</th>\n",
       "      <th>Weeks_in_hot-100</th>\n",
       "      <th>First_Week</th>\n",
       "      <th>Last_Week</th>\n",
       "      <th>Duration</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Tempo_Confidence</th>\n",
       "      <th>Meter_Display</th>\n",
       "      <th>Meter</th>\n",
       "      <th>Meter_Confidence</th>\n",
       "      <th>Key_Display</th>\n",
       "      <th>Key</th>\n",
       "      <th>Key_Confidence</th>\n",
       "      <th>Mode_Display</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Mode_Confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>908</th>\n",
       "      <td>1</td>\n",
       "      <td>Blinding Lights</td>\n",
       "      <td>The Weeknd</td>\n",
       "      <td>90</td>\n",
       "      <td>2019-12-14</td>\n",
       "      <td>2021-09-04</td>\n",
       "      <td>200.04000</td>\n",
       "      <td>-5.934</td>\n",
       "      <td>171.005</td>\n",
       "      <td>0.875</td>\n",
       "      <td>4/4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>C#/Db</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>Major</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5760</th>\n",
       "      <td>3</td>\n",
       "      <td>Radioactive</td>\n",
       "      <td>Kings Of Leon</td>\n",
       "      <td>87</td>\n",
       "      <td>2010-10-02</td>\n",
       "      <td>2014-05-10</td>\n",
       "      <td>206.18668</td>\n",
       "      <td>-4.880</td>\n",
       "      <td>126.405</td>\n",
       "      <td>0.345</td>\n",
       "      <td>4/4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>F</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.468</td>\n",
       "      <td>Major</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.394</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6067</th>\n",
       "      <td>17</td>\n",
       "      <td>Sail</td>\n",
       "      <td>AWOLNATION</td>\n",
       "      <td>79</td>\n",
       "      <td>2011-09-03</td>\n",
       "      <td>2014-03-22</td>\n",
       "      <td>259.09332</td>\n",
       "      <td>-9.583</td>\n",
       "      <td>119.051</td>\n",
       "      <td>0.847</td>\n",
       "      <td>4/4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>C#/Db</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.745</td>\n",
       "      <td>Major</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>2</td>\n",
       "      <td>Levitating</td>\n",
       "      <td>Dua Lipa</td>\n",
       "      <td>77</td>\n",
       "      <td>2020-10-17</td>\n",
       "      <td>2022-05-07</td>\n",
       "      <td>203.06416</td>\n",
       "      <td>-3.787</td>\n",
       "      <td>102.977</td>\n",
       "      <td>0.925</td>\n",
       "      <td>4/4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.994</td>\n",
       "      <td>F#/Gb</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.263</td>\n",
       "      <td>Minor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.220</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3582</th>\n",
       "      <td>6</td>\n",
       "      <td>I'm Yours</td>\n",
       "      <td>Jason Mraz</td>\n",
       "      <td>76</td>\n",
       "      <td>2008-05-03</td>\n",
       "      <td>2009-10-10</td>\n",
       "      <td>242.94667</td>\n",
       "      <td>-9.331</td>\n",
       "      <td>150.960</td>\n",
       "      <td>0.261</td>\n",
       "      <td>4/4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>B</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.592</td>\n",
       "      <td>Major</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.609</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6110</th>\n",
       "      <td>1</td>\n",
       "      <td>Save Your Tears</td>\n",
       "      <td>The Weeknd &amp; Ariana Grande</td>\n",
       "      <td>69</td>\n",
       "      <td>2020-04-04</td>\n",
       "      <td>2022-05-07</td>\n",
       "      <td>215.62666</td>\n",
       "      <td>-5.487</td>\n",
       "      <td>118.051</td>\n",
       "      <td>0.857</td>\n",
       "      <td>4/4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.857</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326</td>\n",
       "      <td>Major</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5493</th>\n",
       "      <td>1</td>\n",
       "      <td>Party Rock Anthem</td>\n",
       "      <td>LMFAO ft. Lauren Bennett &amp; GoonRock</td>\n",
       "      <td>68</td>\n",
       "      <td>2011-02-12</td>\n",
       "      <td>2012-07-21</td>\n",
       "      <td>262.17334</td>\n",
       "      <td>-4.210</td>\n",
       "      <td>129.993</td>\n",
       "      <td>0.616</td>\n",
       "      <td>4/4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>F</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.419</td>\n",
       "      <td>Minor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2946</th>\n",
       "      <td>1</td>\n",
       "      <td>Heat Waves</td>\n",
       "      <td>Glass Animals</td>\n",
       "      <td>68</td>\n",
       "      <td>2021-01-16</td>\n",
       "      <td>2022-05-14</td>\n",
       "      <td>238.80508</td>\n",
       "      <td>-6.900</td>\n",
       "      <td>80.870</td>\n",
       "      <td>0.304</td>\n",
       "      <td>4/4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>B</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.404</td>\n",
       "      <td>Major</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.420</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1499</th>\n",
       "      <td>2</td>\n",
       "      <td>Counting Stars</td>\n",
       "      <td>OneRepublic</td>\n",
       "      <td>68</td>\n",
       "      <td>2013-07-06</td>\n",
       "      <td>2014-10-18</td>\n",
       "      <td>257.84000</td>\n",
       "      <td>-4.972</td>\n",
       "      <td>122.017</td>\n",
       "      <td>0.541</td>\n",
       "      <td>4/4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.909</td>\n",
       "      <td>C#/Db</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.626</td>\n",
       "      <td>Minor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.681</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5983</th>\n",
       "      <td>1</td>\n",
       "      <td>Rolling In The Deep</td>\n",
       "      <td>Adele</td>\n",
       "      <td>65</td>\n",
       "      <td>2010-12-25</td>\n",
       "      <td>2012-04-14</td>\n",
       "      <td>228.09332</td>\n",
       "      <td>-5.114</td>\n",
       "      <td>104.948</td>\n",
       "      <td>0.380</td>\n",
       "      <td>4/4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.966</td>\n",
       "      <td>G#/Ab</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.787</td>\n",
       "      <td>Major</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.659</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>736</th>\n",
       "      <td>8</td>\n",
       "      <td>Before He Cheats</td>\n",
       "      <td>Carrie Underwood</td>\n",
       "      <td>64</td>\n",
       "      <td>2006-09-16</td>\n",
       "      <td>2007-12-01</td>\n",
       "      <td>199.94667</td>\n",
       "      <td>-3.318</td>\n",
       "      <td>147.905</td>\n",
       "      <td>0.444</td>\n",
       "      <td>4/4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.896</td>\n",
       "      <td>F#/Gb</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.609</td>\n",
       "      <td>Minor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.665</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3349</th>\n",
       "      <td>3</td>\n",
       "      <td>I Hope</td>\n",
       "      <td>Gabby Barrett ft. Charlie Puth</td>\n",
       "      <td>62</td>\n",
       "      <td>2020-01-11</td>\n",
       "      <td>2021-03-13</td>\n",
       "      <td>210.77287</td>\n",
       "      <td>-6.227</td>\n",
       "      <td>75.998</td>\n",
       "      <td>0.027</td>\n",
       "      <td>4/4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.723</td>\n",
       "      <td>F#/Gb</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.490</td>\n",
       "      <td>Major</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.594</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8329</th>\n",
       "      <td>5</td>\n",
       "      <td>You And Me</td>\n",
       "      <td>Lifehouse</td>\n",
       "      <td>62</td>\n",
       "      <td>2005-02-12</td>\n",
       "      <td>2010-02-27</td>\n",
       "      <td>195.49333</td>\n",
       "      <td>-7.734</td>\n",
       "      <td>139.902</td>\n",
       "      <td>0.253</td>\n",
       "      <td>3/4</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.835</td>\n",
       "      <td>G</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.709</td>\n",
       "      <td>Major</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.765</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3069</th>\n",
       "      <td>3</td>\n",
       "      <td>Ho Hey</td>\n",
       "      <td>The Lumineers</td>\n",
       "      <td>62</td>\n",
       "      <td>2012-06-23</td>\n",
       "      <td>2013-08-24</td>\n",
       "      <td>163.13333</td>\n",
       "      <td>-9.074</td>\n",
       "      <td>79.936</td>\n",
       "      <td>0.158</td>\n",
       "      <td>4/4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.990</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.466</td>\n",
       "      <td>Major</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.544</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1351</th>\n",
       "      <td>1</td>\n",
       "      <td>Circles</td>\n",
       "      <td>Post Malone</td>\n",
       "      <td>61</td>\n",
       "      <td>2019-09-14</td>\n",
       "      <td>2020-12-05</td>\n",
       "      <td>215.28000</td>\n",
       "      <td>-3.497</td>\n",
       "      <td>120.042</td>\n",
       "      <td>0.746</td>\n",
       "      <td>4/4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.995</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.674</td>\n",
       "      <td>Major</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.733</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1704</th>\n",
       "      <td>6</td>\n",
       "      <td>Demons</td>\n",
       "      <td>Imagine Dragons</td>\n",
       "      <td>61</td>\n",
       "      <td>2013-01-26</td>\n",
       "      <td>2020-05-23</td>\n",
       "      <td>175.20000</td>\n",
       "      <td>-3.015</td>\n",
       "      <td>89.938</td>\n",
       "      <td>0.074</td>\n",
       "      <td>4/4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>D#/Eb</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.461</td>\n",
       "      <td>Major</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4973</th>\n",
       "      <td>2</td>\n",
       "      <td>Need You Now</td>\n",
       "      <td>Lady Antebellum</td>\n",
       "      <td>60</td>\n",
       "      <td>2009-08-29</td>\n",
       "      <td>2011-02-26</td>\n",
       "      <td>277.57333</td>\n",
       "      <td>-5.535</td>\n",
       "      <td>107.943</td>\n",
       "      <td>0.716</td>\n",
       "      <td>4/4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.855</td>\n",
       "      <td>E</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.485</td>\n",
       "      <td>Major</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.541</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>329</th>\n",
       "      <td>1</td>\n",
       "      <td>All Of Me</td>\n",
       "      <td>John Legend</td>\n",
       "      <td>59</td>\n",
       "      <td>2013-09-21</td>\n",
       "      <td>2014-12-06</td>\n",
       "      <td>269.56000</td>\n",
       "      <td>-7.064</td>\n",
       "      <td>119.930</td>\n",
       "      <td>0.011</td>\n",
       "      <td>4/4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.665</td>\n",
       "      <td>G#/Ab</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.442</td>\n",
       "      <td>Major</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6230</th>\n",
       "      <td>1</td>\n",
       "      <td>Shape Of You</td>\n",
       "      <td>Ed Sheeran</td>\n",
       "      <td>59</td>\n",
       "      <td>2017-01-28</td>\n",
       "      <td>2018-03-03</td>\n",
       "      <td>233.71265</td>\n",
       "      <td>-3.183</td>\n",
       "      <td>95.977</td>\n",
       "      <td>0.261</td>\n",
       "      <td>4/4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.981</td>\n",
       "      <td>C#/Db</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.728</td>\n",
       "      <td>Minor</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6517</th>\n",
       "      <td>1</td>\n",
       "      <td>Somebody That I Used To Know</td>\n",
       "      <td>Gotye ft. Kimbra</td>\n",
       "      <td>59</td>\n",
       "      <td>2012-01-21</td>\n",
       "      <td>2014-06-07</td>\n",
       "      <td>244.97333</td>\n",
       "      <td>-7.036</td>\n",
       "      <td>129.062</td>\n",
       "      <td>0.884</td>\n",
       "      <td>4/4</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.000</td>\n",
       "      <td>C</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.738</td>\n",
       "      <td>Major</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.991</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      Top_Rank                         Title  \\\n",
       "908          1               Blinding Lights   \n",
       "5760         3                   Radioactive   \n",
       "6067        17                          Sail   \n",
       "4175         2                    Levitating   \n",
       "3582         6                     I'm Yours   \n",
       "6110         1               Save Your Tears   \n",
       "5493         1             Party Rock Anthem   \n",
       "2946         1                    Heat Waves   \n",
       "1499         2                Counting Stars   \n",
       "5983         1           Rolling In The Deep   \n",
       "736          8              Before He Cheats   \n",
       "3349         3                        I Hope   \n",
       "8329         5                    You And Me   \n",
       "3069         3                        Ho Hey   \n",
       "1351         1                       Circles   \n",
       "1704         6                        Demons   \n",
       "4973         2                  Need You Now   \n",
       "329          1                     All Of Me   \n",
       "6230         1                  Shape Of You   \n",
       "6517         1  Somebody That I Used To Know   \n",
       "\n",
       "                                   Artist  Weeks_in_hot-100  First_Week  \\\n",
       "908                            The Weeknd                90  2019-12-14   \n",
       "5760                        Kings Of Leon                87  2010-10-02   \n",
       "6067                           AWOLNATION                79  2011-09-03   \n",
       "4175                             Dua Lipa                77  2020-10-17   \n",
       "3582                           Jason Mraz                76  2008-05-03   \n",
       "6110           The Weeknd & Ariana Grande                69  2020-04-04   \n",
       "5493  LMFAO ft. Lauren Bennett & GoonRock                68  2011-02-12   \n",
       "2946                        Glass Animals                68  2021-01-16   \n",
       "1499                          OneRepublic                68  2013-07-06   \n",
       "5983                                Adele                65  2010-12-25   \n",
       "736                      Carrie Underwood                64  2006-09-16   \n",
       "3349       Gabby Barrett ft. Charlie Puth                62  2020-01-11   \n",
       "8329                            Lifehouse                62  2005-02-12   \n",
       "3069                        The Lumineers                62  2012-06-23   \n",
       "1351                          Post Malone                61  2019-09-14   \n",
       "1704                      Imagine Dragons                61  2013-01-26   \n",
       "4973                      Lady Antebellum                60  2009-08-29   \n",
       "329                           John Legend                59  2013-09-21   \n",
       "6230                           Ed Sheeran                59  2017-01-28   \n",
       "6517                     Gotye ft. Kimbra                59  2012-01-21   \n",
       "\n",
       "       Last_Week   Duration  Loudness    Tempo  Tempo_Confidence  \\\n",
       "908   2021-09-04  200.04000    -5.934  171.005             0.875   \n",
       "5760  2014-05-10  206.18668    -4.880  126.405             0.345   \n",
       "6067  2014-03-22  259.09332    -9.583  119.051             0.847   \n",
       "4175  2022-05-07  203.06416    -3.787  102.977             0.925   \n",
       "3582  2009-10-10  242.94667    -9.331  150.960             0.261   \n",
       "6110  2022-05-07  215.62666    -5.487  118.051             0.857   \n",
       "5493  2012-07-21  262.17334    -4.210  129.993             0.616   \n",
       "2946  2022-05-14  238.80508    -6.900   80.870             0.304   \n",
       "1499  2014-10-18  257.84000    -4.972  122.017             0.541   \n",
       "5983  2012-04-14  228.09332    -5.114  104.948             0.380   \n",
       "736   2007-12-01  199.94667    -3.318  147.905             0.444   \n",
       "3349  2021-03-13  210.77287    -6.227   75.998             0.027   \n",
       "8329  2010-02-27  195.49333    -7.734  139.902             0.253   \n",
       "3069  2013-08-24  163.13333    -9.074   79.936             0.158   \n",
       "1351  2020-12-05  215.28000    -3.497  120.042             0.746   \n",
       "1704  2020-05-23  175.20000    -3.015   89.938             0.074   \n",
       "4973  2011-02-26  277.57333    -5.535  107.943             0.716   \n",
       "329   2014-12-06  269.56000    -7.064  119.930             0.011   \n",
       "6230  2018-03-03  233.71265    -3.183   95.977             0.261   \n",
       "6517  2014-06-07  244.97333    -7.036  129.062             0.884   \n",
       "\n",
       "     Meter_Display  Meter  Meter_Confidence Key_Display   Key  Key_Confidence  \\\n",
       "908            4/4    4.0             1.000       C#/Db   1.0           0.000   \n",
       "5760           4/4    4.0             1.000           F   5.0           0.468   \n",
       "6067           4/4    4.0             1.000       C#/Db   1.0           0.745   \n",
       "4175           4/4    4.0             0.994       F#/Gb   6.0           0.263   \n",
       "3582           4/4    4.0             1.000           B  11.0           0.592   \n",
       "6110           4/4    4.0             0.857           C   0.0           0.326   \n",
       "5493           4/4    4.0             1.000           F   5.0           0.419   \n",
       "2946           4/4    4.0             1.000           B  11.0           0.404   \n",
       "1499           4/4    4.0             0.909       C#/Db   1.0           0.626   \n",
       "5983           4/4    4.0             0.966       G#/Ab   8.0           0.787   \n",
       "736            4/4    4.0             0.896       F#/Gb   6.0           0.609   \n",
       "3349           4/4    4.0             0.723       F#/Gb   6.0           0.490   \n",
       "8329           3/4    3.0             0.835           G   7.0           0.709   \n",
       "3069           4/4    4.0             0.990           C   0.0           0.466   \n",
       "1351           4/4    4.0             0.995           C   0.0           0.674   \n",
       "1704           4/4    4.0             1.000       D#/Eb   3.0           0.461   \n",
       "4973           4/4    4.0             0.855           E   4.0           0.485   \n",
       "329            4/4    4.0             0.665       G#/Ab   8.0           0.442   \n",
       "6230           4/4    4.0             0.981       C#/Db   1.0           0.728   \n",
       "6517           4/4    4.0             1.000           C   0.0           0.738   \n",
       "\n",
       "     Mode_Display  Mode  Mode_Confidence  \n",
       "908         Major   1.0            0.152  \n",
       "5760        Major   1.0            0.394  \n",
       "6067        Major   1.0            0.447  \n",
       "4175        Minor   0.0            0.220  \n",
       "3582        Major   1.0            0.609  \n",
       "6110        Major   1.0            0.500  \n",
       "5493        Minor   0.0            0.483  \n",
       "2946        Major   1.0            0.420  \n",
       "1499        Minor   0.0            0.681  \n",
       "5983        Major   1.0            0.659  \n",
       "736         Minor   0.0            0.665  \n",
       "3349        Major   1.0            0.594  \n",
       "8329        Major   1.0            0.765  \n",
       "3069        Major   1.0            0.544  \n",
       "1351        Major   1.0            0.733  \n",
       "1704        Major   1.0            0.564  \n",
       "4973        Major   1.0            0.541  \n",
       "329         Major   1.0            0.579  \n",
       "6230        Minor   0.0            0.647  \n",
       "6517        Major   1.0            0.991  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read in the Spotify and Billboard data combined\n",
    "df = pd.read_csv(\"csv/spotify_data_2000_01_01.csv\").iloc[:, 1:]\n",
    "# Drop the missing data\n",
    "df = df.dropna()\n",
    "\n",
    "# Returns a string with the correctly formatted time signature (no longer a float)\n",
    "def display_time_sig(time_sig):\n",
    "    return str(int(time_sig)) + \"/4\"\n",
    "\n",
    "# Returns a string corresponding to the key identified by pitch class\n",
    "def display_key(key):\n",
    "    if key == 0:\n",
    "        return \"C\"\n",
    "    elif key == 1:\n",
    "        return \"C#/Db\"\n",
    "    elif key == 2:\n",
    "        return \"D\"\n",
    "    elif key == 3:\n",
    "        return \"D#/Eb\"\n",
    "    elif key == 4:\n",
    "        return \"E\"\n",
    "    elif key == 5:\n",
    "        return \"F\"\n",
    "    elif key == 6:\n",
    "        return \"F#/Gb\"\n",
    "    elif key == 7:\n",
    "        return \"G\"\n",
    "    elif key == 8:\n",
    "        return \"G#/Ab\"\n",
    "    elif key == 9:\n",
    "        return \"A\"\n",
    "    elif key == 10:\n",
    "        return \"A#/Bb\"\n",
    "    elif key == 11:\n",
    "        return \"B\"\n",
    "    else:\n",
    "        return \"Error\"\n",
    "\n",
    "# Returns true if the mode is major\n",
    "def display_mode(num):\n",
    "    return \"Major\" if num > 0 else \"Minor\"\n",
    "\n",
    "# Update the columns\n",
    "\n",
    "df.insert(10, \"Meter_Display\", df[\"Meter\"].apply(display_time_sig), False)\n",
    "df.insert(13, \"Key_Display\", df[\"Key\"].apply(display_key), False)\n",
    "df.insert(16, \"Mode_Display\", df[\"Mode\"].apply(display_mode), False)\n",
    "df.sort_values(by=['Weeks_in_hot-100'], ascending=False, inplace=True)\n",
    "df.head(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.12 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
